# Developer Performance Analytics Guide

## Overview

The SDM-Tools analytics module provides comprehensive, industry-standard insights into developer performance using data from Git commits and Jira issues. This guide explains the metrics, scoring algorithms, and actionable insights generated by the system.

## Key Performance Indicators (KPIs)

### 1. Productivity Score (0-100)
**Purpose**: Measures overall developer output and efficiency

**Components**:
- **Commit Frequency** (30 points max): Based on commits per day
- **Issue Resolution** (25 points max): Number of issues resolved
- **Story Points** (25 points max): Story points completed
- **Consistency** (20 points max): Days active over 30-day period

**Industry Benchmarks**:
- 70-100: High performer
- 40-69: Average performer
- 0-39: Needs improvement

### 2. Collaboration Score (0-100)
**Purpose**: Evaluates team interaction and collaborative practices

**Components**:
- **Merge Ratio** (50 points max): Percentage of merge commits (indicates code reviews)
- **Issue Creation** (50 points max): Engagement with team processes

**Industry Benchmarks**:
- 60-100: Strong collaborator
- 30-59: Moderate collaboration
- 0-29: Limited collaboration

### 3. Code Quality Score (0-100)
**Purpose**: Assesses code quality based on commit patterns

**Quality Indicators**:
- Bug fixes and issue references
- Test-related commits
- Refactoring and optimization
- Descriptive commit messages (>20 characters)

**Industry Benchmarks**:
- 80-100: Excellent quality practices
- 60-79: Good quality practices
- 40-59: Average quality practices
- 0-39: Quality improvement needed

## Detailed Metrics

### Git Commit Analysis
- **Total Commits**: Raw commit count
- **Commit Frequency**: Commits per day average
- **Peak Activity Patterns**: Most active day of week and hour
- **Merge Commit Ratio**: Percentage indicating collaboration
- **Activity Span**: Days between first and last commit

### Jira Issue Analysis
- **Issues Created**: Tickets created by developer
- **Issues Assigned**: Tickets assigned to developer
- **Issues Resolved**: Tickets completed
- **Average Resolution Time**: Days from creation to completion
- **Story Points**: Complexity/effort completed
- **Priority Distribution**: Types of issues handled

## Team Insights

### Performance Categories
1. **Top Performers**: Top 20% by productivity score
2. **Growth Opportunities**: Bottom 20% needing support
3. **Collaboration Leaders**: Highest collaboration scores
4. **Quality Champions**: Highest code quality scores

### Workload Analysis
- Distribution of assigned issues across team
- Identification of overloaded or underutilized developers
- Workload balance recommendations

### Automated Recommendations

The system generates actionable recommendations based on:

#### Low Productivity (< 50 average)
- Review sprint planning processes
- Identify and remove blockers
- Consider workload redistribution

#### Poor Collaboration (< 40 average)
- Encourage pair programming
- Implement mandatory code reviews
- Increase team communication

#### Quality Issues (< 60 average)
- Establish commit message standards
- Implement code review processes
- Provide quality training

#### Workload Imbalance
- High standard deviation in issue assignments
- Recommendations for task rebalancing

#### Long Resolution Times (> 14 days average)
- Review issue complexity
- Provide additional support or training
- Break down large tasks

#### Low Commit Frequency (< 0.5 per day)
- Encourage smaller, more frequent commits
- Review development workflow
- Address potential blockers

## Data Sources and Calculations

### Git Commit Data
```sql
SELECT author_name, author_email, date, message, hash
FROM git_commits 
ORDER BY date
```

### Jira Issue Data
```sql
-- Created issues
SELECT creator, created, status, priority, summary, assignee, updated, customfield_10026
FROM iotmi_3p_issues 
WHERE creator IS NOT NULL

-- Assigned issues  
SELECT assignee, created, status, priority, summary, updated, customfield_10026
FROM iotmi_3p_issues 
WHERE assignee IS NOT NULL
```

## Scoring Algorithms

### Productivity Score Calculation
```python
commit_score = min(commit_frequency * 10, 30)
resolution_score = min(issues_resolved * 5, 25)
story_points_score = min(story_points * 2, 25)
consistency_score = min(days_active / 30 * 20, 20)

productivity_score = min(commit_score + resolution_score + story_points_score + consistency_score, 100)
```

### Collaboration Score Calculation
```python
merge_score = min(merge_ratio * 50, 50)
creation_score = min(issues_created * 5, 50)

collaboration_score = min(merge_score + creation_score, 100)
```

### Code Quality Score Calculation
```python
quality_indicators = 0
for commit in commits:
    if 'fix' or 'bug' in message: quality_indicators += 1
    if 'test' or 'spec' in message: quality_indicators += 1
    if 'refactor' or 'clean' in message: quality_indicators += 1
    if len(message) > 20: quality_indicators += 1

quality_ratio = quality_indicators / (total_commits * 4)
code_quality_score = min(quality_ratio * 100, 100)
```

## Data Persistence

### Analytics Database Table
```sql
CREATE TABLE developer_analytics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    analysis_date TEXT,
    developer_name TEXT,
    developer_email TEXT,
    commit_count INTEGER,
    commit_frequency REAL,
    avg_commits_per_day REAL,
    peak_commit_day TEXT,
    peak_commit_hour INTEGER,
    issues_created INTEGER,
    issues_assigned INTEGER,
    issues_resolved INTEGER,
    avg_resolution_time REAL,
    story_points_completed REAL,
    productivity_score REAL,
    collaboration_score REAL,
    code_quality_score REAL,
    UNIQUE(analysis_date, developer_email)
)
```

## Usage Instructions

### Running Analytics
1. Ensure you have both Git commits and Jira data in the database
2. Run the CLI tool: `python -m sdm_tools.cli`
3. Select option 5: "Generate Developer Performance Analytics"
4. Review the comprehensive report generated

### Interpreting Results
- **Team Summary**: Overall team performance overview
- **Top Performers Table**: Ranked list of developers by productivity
- **Team Insights**: Categorized performance analysis
- **Recommendations**: Actionable improvement suggestions
- **Detailed Metrics**: Individual developer profiles (optional)

### Best Practices
1. Run analytics regularly (weekly/monthly) to track trends
2. Use insights for 1:1 meetings and performance reviews
3. Focus on improvement opportunities rather than just rankings
4. Consider external factors that may affect metrics
5. Use data to support, not replace, human judgment

## Industry Standards and Benchmarks

### Commit Frequency
- **High**: 1+ commits per day
- **Average**: 0.5-1 commits per day
- **Low**: <0.5 commits per day

### Issue Resolution
- **Fast**: <7 days average
- **Average**: 7-14 days
- **Slow**: >14 days

### Code Quality Indicators
- Descriptive commit messages
- Regular refactoring
- Test coverage commits
- Bug fix documentation

### Collaboration Metrics
- Code review participation
- Merge commit frequency
- Issue creation and discussion
- Knowledge sharing activities

## Limitations and Considerations

### Data Quality Dependencies
- Accuracy depends on consistent Git commit practices
- Jira data completeness affects issue metrics
- Custom field mappings may need adjustment

### Context Factors
- Project complexity variations
- Team size and structure
- Development methodology differences
- External dependencies and blockers

### Ethical Considerations
- Use for development, not punishment
- Consider individual circumstances
- Focus on team improvement
- Maintain developer privacy and trust

## Future Enhancements

### Planned Features
- Trend analysis over time
- Comparative team analytics
- Integration with additional tools
- Custom metric definitions
- Automated alerting for performance issues

### Advanced Analytics
- Predictive performance modeling
- Burnout risk indicators
- Skill gap analysis
- Project success correlation

---

*This analytics system is designed to provide objective insights while respecting the human aspects of software development. Use these metrics as a starting point for meaningful conversations about growth and improvement.*
